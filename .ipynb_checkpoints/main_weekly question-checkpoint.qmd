---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: CHEERUP's FSDS Group Project
execute:
  echo: false
format:
  html:
    theme:
      - minty
      - css/web.scss
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Spectral
    sansfont: Roboto
    monofont: JetBrainsMono-Regular
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Declaration of Authorship {.unnumbered .unlisted}

We, [insert your group's names], confirm that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.

Date:

Student Numbers: 

## Brief Group Reflection

| What Went Well | What Was Challenging |
| -------------- | -------------------- |
| A              | B                    |
| C              | D                    |

## Priorities for Feedback

Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?

{{< pagebreak >}}

# Response to Questions

```{python}
import os
import pandas as pd
```

```{python}
# host = 'https://orca.casa.ucl.ac.uk'
# path = '~jreades/data'
# file = '2022-09-10-listings.csv.gz'
# url  = f'{host}/{path}/{file}'

# if os.path.exists(os.pathdatafile):
#   df = pd.read_csv(file, compression='gzip', low_memory=False)
# else: 
#   df = pd.read_csv(url, compression='gzip', low_memory=False)
#   df.to_csv(file)
```

```{python}
# Read file in the data folder. The file is extracted from insideairbnb.com on Nov 13, 2023

df = pd.read_csv(os.path.join('data','listings.csv.gz'), compression='gzip', low_memory=False)
```

## 1. Who collected the data?

Inside Airbnb was founded by Murray Cox, an artist, activist and technologist who conceived the project, compiled and analyzed the data and built the site. @insideairbnb
 

## 2. Why did they collect it?

- To increase transparency about Airbnb. Inside Airbnb wants to make it easier for people to understand how Airbnb is affecting their communities.
- To hold Airbnb accountable for its impact. Inside Airbnb wants Airbnb to be more transparent about its data and to take steps to mitigate the negative impacts of its busines
- 
To promote responsible short-term rentals. Inside Airbnb believes that short-term rentals can be a positive thing for communities, but it believes that they need to be regulated to ensure that they are not harming local residen.

```{python}
print(f"Data frame is {df.shape[0]:,} x {df.shape[1]:,}")
```

```{python}
ax = df.host_listings_count.plot.hist(bins=50);
ax.set_xlim([0,500]);
```

## 3. How was the data collected?  

Inside Airbnb uses web scraping scripts to extract information from Airbnb's website. These scripts navigate through the Airbnb site, access pages, and get data such as listings, hosts, pricing, etc. The collected data is then processed and made available on the Inside Airbnb website for users to explore and analyze.

## 4. How does the method of collection impact the completeness and/or accuracy of its representation of the process it seeks to study, and what wider issues does this raise?

1. Pricing and availability among others are extremely dynamic attributes set by hosts that cannot be captured accurately with webscraping, which only reflects a snapshot of the website at one specific moment in time.
2. Susceptible to changes in the structure of the website.
3. Web scraping only accesses pubicly available listings.
4. Too frequent web scraping may affect site performance which in turns affect the data scraped
5. Has to ethical and legal implications

## 5. What ethical considerations does the use of this data raise? 

::: {.duedate}

( 18 points; Answer due {{< var assess.group-date >}} )

:::

## 6. With reference to the data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )

:::

## 7. Drawing on your previous answers, and supporting your response with evidence (e.g. figures, maps, and statistical analysis/models), how *could* this data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}

( 45 points; Answer due {{< var assess.group-date >}} )

:::

## Sustainable Authorship Tools

Your QMD file should automatically download your BibTeX file. We will then re-run the QMD file to generate the output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References
